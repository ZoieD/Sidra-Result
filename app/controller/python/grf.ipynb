{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense,Dropout,Activation,Input\n",
    "from keras.models import Sequential,Model\n",
    "from keras import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from grf file get data\n",
    "def get_data(filename):\n",
    "    df = pd.read_table(filename)\n",
    "# def get_data():\n",
    "#     df = pd.read_table('data/02_052A.grf')\n",
    "    t = df.loc[df['DPLOT v1.6'].str.contains(r'\\s+[0]$')].index.tolist()\n",
    "    arr = df.values\n",
    "    data_class = int(df.iat[1, 0])\n",
    "    data_name = []\n",
    "    normalised_x = []\n",
    "    normalised_y = []\n",
    "    for i in range(data_class):\n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        data_name.append(df.iat[int(t[i])+1,0])\n",
    "        if i == 0:\n",
    "            x1 = df[3:int(t[i])].values\n",
    "            for j in range(x1.shape[0]):\n",
    "                data_x.append(''.join(x1[j]).split(',')[0])\n",
    "                data_y.append(''.join(x1[j]).split(',')[1])\n",
    "        else:\n",
    "            x2 = df[int(t[i-1])+3:int(t[i])].values\n",
    "            for k in range(x2.shape[0]):\n",
    "                data_x.append(''.join(x2[k]).split(',')[0])\n",
    "                data_y.append(''.join(x2[k]).split(',')[1])\n",
    "        normalised_x.append(np.array(data_x))\n",
    "        normalised_y.append(np.array(data_y))\n",
    "#     print('2222',normalised_x,\"333\",normalised_y)\n",
    "    data_class = str(df.iat[t[-1]+5, 0])\n",
    "    if \"Pressure\" in data_class:\n",
    "        data_class = 'Pressure'\n",
    "    else:\n",
    "        data_class = 'Impulses'\n",
    "    title = df.iat[t[-1]+3,0].replace(\"(\",\"\").replace(\")\",\"\")\n",
    "    N = title.split(', ')[0].split(' = ')[1]\n",
    "    lL = title.split(', ')[1].split(' = ')[1]\n",
    "    hH = title.split(', ')[2].split(' = ')[1]\n",
    "    LH = title.split(', ')[3].split(' = ')[1]\n",
    "    return data_class, N, lL, hH, LH, np.array(data_name),np.array(normalised_x),np.array(normalised_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 11,661\n",
      "Trainable params: 11,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model create\n",
    "def make_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(units=100,activation='relu',input_dim=2))\n",
    "#     model.add(Dropout(0.05))\n",
    "    model.add(Dense(units=80,activation='relu'))\n",
    "    model.add(Dense(units=40,activation='relu'))\n",
    "#     model.add(Dropout(0.05))\n",
    "    model.add(Dense(units=1,activation=None))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=[metrics.mae])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processer_data(data_class, N, lL, hH, LH, data_name, normalised_x, normalised_y):\n",
    "    if data_class == 'Pressure':\n",
    "        for i in range(len(data_name)):\n",
    "            trainp = []\n",
    "            for j in range(len(normalised_x[i])):\n",
    "                trainp.append([N, lL, hH, LH, data_name[i]])\n",
    "            trainp = np.array(trainp).reshape(-1, 5)\n",
    "            xp.append(trainp)\n",
    "        xp = np.array(xp).reshape(-1,5)\n",
    "        yp = np.array(normalised_y).reshape(-1,1)\n",
    "#             print(np.shape(xp), xp,np.shape(yp),yp)\n",
    "    else:\n",
    "        for i in range(len(data_name)):\n",
    "            traini = []\n",
    "            for j in range(len(normalised_x[i])):\n",
    "                traini.append([N, lL, hH, LH, data_name[i]])\n",
    "            traini = np.array(traini).reshape(-1, 5)\n",
    "            xi.append(traini)\n",
    "        xi = np.array(xi).reshape(-1,5)\n",
    "        yi = np.array(normalised_y).reshape(-1,1)\n",
    "#         print(np.shape(x), x,np.shape(y),y)\n",
    "    pressure_x.append(xp)\n",
    "    pressure_y.append(yp)\n",
    "    impulses_x.append(xi)\n",
    "    impulses_y.append(yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Traverse all grf files in folder\n",
    "#Process data to train data\n",
    "dataDir = './data'\n",
    "pressure_x = []\n",
    "pressure_y = []\n",
    "impulses_x = []\n",
    "impulses_y = []\n",
    "for dirName, subdirList, fileList in os.walk(dataDir):\n",
    "    print('Found directory: %s' % dirName)\n",
    "    for fname in fileList:\n",
    "        xi = []\n",
    "        yi = []\n",
    "        xp = []\n",
    "        yp = []\n",
    "        filename = str(dirName + '/' + fname)\n",
    "        data_class, N, lL, hH, LH, data_name, normalised_x, normalised_y = get_data(filename)\n",
    "        if data_class == 'Pressure':\n",
    "            for i in range(len(data_name)):\n",
    "                trainp = []\n",
    "                for j in range(len(normalised_x[i])):\n",
    "                    trainp.append([N, lL, hH, LH, data_name[i]])\n",
    "                trainp = np.array(trainp).reshape(-1, 5)\n",
    "                xp.append(trainp)\n",
    "            xp = np.array(xp).reshape(-1,5)\n",
    "            yp = np.array(normalised_y).reshape(-1,1)\n",
    "#             print(np.shape(xp), xp,np.shape(yp),yp)\n",
    "        else:\n",
    "            for i in range(len(data_name)):\n",
    "                traini = []\n",
    "                for j in range(len(normalised_x[i])):\n",
    "                    traini.append([N, lL, hH, LH, data_name[i]])\n",
    "                traini = np.array(traini).reshape(-1, 5)\n",
    "                xi.append(traini)\n",
    "            xi = np.array(xi).reshape(-1,5)\n",
    "            yi = np.array(normalised_y).reshape(-1,1)\n",
    "    #         print(np.shape(x), x,np.shape(y),y)\n",
    "        pressure_x.append(xp)\n",
    "        pressure_y.append(yp)\n",
    "        impulses_x.append(xi)\n",
    "        impulses_y.append(yi)\n",
    "#         print(np.shape(pressure_x), pressure_x,np.shape(pressure_y),pressure_y)\n",
    "    pressure_x_train = np.array(pressure_x).reshape(-1,5)\n",
    "    pressure_y_train = np.array(pressure_y).reshape(-1,1)\n",
    "    impulses_x_train = np.array(impulses_x).reshape(-1,5)\n",
    "    impulses_y_train = np.array(impulses_y).reshape(-1,1)\n",
    "    print(np.shape(pressure_x_train),pressure_x_train,np.shape(pressure_y_train),pressure_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=1, epochs=10, verbose=1)\n",
    "model.save_weights('modules/module.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4417.6875]]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('modules/module.h5',by_name=False)\n",
    "x_test = np.array([[1, 1]])\n",
    "pred=model.predict(x_test)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
